{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path): \n",
    "    df = pd.read_json(path, lines = True)\n",
    "    return df \n",
    "\n",
    "def write_file(path, file, text): \n",
    "    pathname = os.path.join(path, file)\n",
    "    outfile = open(pathname, 'w')\n",
    "    for instance in text:\n",
    "        outfile.write(json.dumps(instance) + '\\n')\n",
    "    outfile.close()\n",
    "    \n",
    "def listToString(df, column): \n",
    "    listToString = []\n",
    "    for i in df[column]:\n",
    "        i = ', '.join(i)\n",
    "        i = ' '.join(s for s in i.split() if not any(c.isdigit() for c in s))\n",
    "        i = i.replace(',', '')\n",
    "        listToString.append(i)\n",
    "    return listToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_vectorising (source, target): \n",
    "    # convert training data to bag of words\n",
    "    cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2), stop_words='english')\n",
    "    X_train_cv = cv.fit_transform(source['train'])\n",
    "    X_test_cv = cv.transform(target['train'])\n",
    "    Y_train = source['sentiment'].astype('int')\n",
    "    Y_test = target['sentiment'].astype('int')\n",
    "    \n",
    "    # train model and generate predictions\n",
    "    model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    model.fit(X_train_cv, Y_train)\n",
    "    train_yhat = model.predict(X_train_cv)\n",
    "    train_acc = accuracy_score(Y_train, train_yhat)\n",
    "    test_yhat = model.predict(X_test_cv)\n",
    "    test_acc = accuracy_score(Y_test, test_yhat)\n",
    "    \n",
    "    \n",
    "    # compute f-1 score\n",
    "    #score = np.round(f1_score(target['sentiment'].astype('int'), y_pred, average='micro'),4)\n",
    "    #score_training = np.round(f1_score(source['sentiment'].astype('int'), y_pred, average='micro'),4)\n",
    "    precision = precision_score(Y_test, test_yhat, labels=[1,2], average='micro')\n",
    "    recall = recall_score(Y_test, test_yhat, labels=[1,2], average='micro')\n",
    "    score = f1_score(Y_test, test_yhat, average='binary')\n",
    "    accuracy = test_acc\n",
    "    misclassified_samples = np.flatnonzero(Y_test != test_yhat)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", score)\n",
    "    print(misclassified_samples)\n",
    "    #print(\"Accuracy test: \", test_acc)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Source Proporsed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8899082568807339\n",
      "Recall:  0.8818181818181818\n",
      "F1 Score:  0.8858447488584476\n",
      "[  7  16  20  44  52  53  57  63  65  74  87  94 110 118 121 136 137 148\n",
      " 150 162 198 206 207 211 215]\n"
     ]
    }
   ],
   "source": [
    "source_B = read_data('data/proposed/source_B.json')\n",
    "target_music_B = read_data('data/proposed/target_music_B.json')\n",
    "source_B = source_B[source_B['sentiment'] != '-']\n",
    "acc_B = training_vectorising(source_B, target_music_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8260869565217391\n",
      "Recall:  0.8636363636363636\n",
      "F1 Score:  0.8444444444444444\n",
      "[  2  12  18  20  24  28  32  39  40  42  56  63  64  73  79  87  93  98\n",
      "  99 105 115 121 134 136 137 146 149 156 171 176 183 206 207 211 214]\n"
     ]
    }
   ],
   "source": [
    "source_E = read_data('data/proposed/source_E.json')\n",
    "target_music_E = read_data('data/proposed/target_music_E.json')\n",
    "source_E = source_E[source_E['sentiment'] != '-']\n",
    "acc_E = training_vectorising(source_E, target_music_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8673469387755102\n",
      "Recall:  0.7727272727272727\n",
      "F1 Score:  0.8173076923076923\n",
      "[  0   1  32  34  38  39  40  59  63  79  93  94 108 115 118 119 121 134\n",
      " 145 146 149 156 162 163 165 166 171 176 178 191 198 199 206 207 210 212\n",
      " 214 218]\n"
     ]
    }
   ],
   "source": [
    "source_P = read_data('data/proposed/source_P.json')\n",
    "target_music_P = read_data('data/proposed/target_music_P.json')\n",
    "source_P = source_P[source_P['sentiment'] != '-']\n",
    "acc_P = training_vectorising(source_P, target_music_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sources Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8990825688073395\n",
      "Recall:  0.8909090909090909\n",
      "F1 Score:  0.8949771689497716\n",
      "[  0  17  18  32  40  57  78  79  94  99 101 115 121 134 146 149 156 162\n",
      " 171 176 206 207 215]\n"
     ]
    }
   ],
   "source": [
    "source_EP = read_data('data/proposed/source_EP.json')\n",
    "target_music_EP = read_data('data/proposed/target_music_EP.json')\n",
    "source_EP = source_EP[source_EP['sentiment'] != '-']\n",
    "acc_EP = training_vectorising(source_EP, target_music_EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8348623853211009\n",
      "Recall:  0.8272727272727273\n",
      "F1 Score:  0.8310502283105023\n",
      "[  0   2   3   7  10  14  30  32  40  41  45  63  72  78  86  93  98 105\n",
      " 110 115 118 121 134 137 146 149 156 162 171 175 176 198 206 207 210 215\n",
      " 218]\n"
     ]
    }
   ],
   "source": [
    "source_BP = read_data('data/proposed/source_BP.json')\n",
    "target_music_BP = read_data('data/proposed/target_music_BP.json')\n",
    "source_BP = source_BP[source_BP['sentiment'] != '-']\n",
    "acc_BP = training_vectorising(source_BP, target_music_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8666666666666667\n",
      "Recall:  0.8272727272727273\n",
      "F1 Score:  0.8465116279069769\n",
      "[  0   7  24  34  44  55  62  79  94  96  97  98  99 105 110 115 119 121\n",
      " 123 134 136 137 146 149 156 160 162 176 195 206 211 214 215]\n"
     ]
    }
   ],
   "source": [
    "source_BE = read_data('data/proposed/source_BE.json')\n",
    "target_music_BE = read_data('data/proposed/target_music_BE.json')\n",
    "source_BE = source_BE[source_BE['sentiment'] != '-']\n",
    "acc_BE = training_vectorising(source_BE, target_music_BE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Sources Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8962264150943396\n",
      "Recall:  0.8636363636363636\n",
      "F1 Score:  0.8796296296296295\n",
      "[  0  32  39  40  48  49  57  79  93  94  99 110 114 115 121 134 146 149\n",
      " 156 162 163 176 183 206 210 214]\n"
     ]
    }
   ],
   "source": [
    "source_BEP = read_data('data/proposed/source_BEP.json')\n",
    "target_music_BEP = read_data('data/proposed/target_music_BEP.json')\n",
    "source_BEP = source_BEP[source_BEP['sentiment'] != '-']\n",
    "acc_BEP = training_vectorising(source_BEP, target_music_BEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Source Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "noadaption_target = read_data('data/processed/target_music.json')\n",
    "noadaption_target['train'] = listToString(noadaption_target, 'unigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6533333333333333\n",
      "Recall:  0.8909090909090909\n",
      "F1 Score:  0.7538461538461538\n",
      "[  0   4   5   7  11  12  14  18  19  20  21  23  24  26  28  32  34  39\n",
      "  40  44  45  47  48  49  52  55  57  61  64  67  69  72  73  74  76  79\n",
      "  80  84  85  87  88  89  91  92  93  94  96  98  99 105 107 108 110 136\n",
      " 137 148 162 171 195 198 206 207 210 211]\n"
     ]
    }
   ],
   "source": [
    "noadaption_books = read_data('data/processed/source_B.json')\n",
    "noadaption_books['train'] = listToString(noadaption_books, 'unigrams')\n",
    "noadaption_books = noadaption_books[noadaption_books['sentiment'] != '-']\n",
    "acc_B_noadaption = training_vectorising(noadaption_books, noadaption_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7054263565891473\n",
      "Recall:  0.8272727272727273\n",
      "F1 Score:  0.7615062761506277\n",
      "[  0   1   2   4   8  10  12  13  16  21  23  24  26  32  34  39  40  46\n",
      "  55  57  63  64  67  69  72  76  79  85  88  89  92  93  94  96  98  99\n",
      " 105 108 115 121 134 136 146 152 156 162 171 176 192 195 196 198 206 207\n",
      " 210 211 218]\n"
     ]
    }
   ],
   "source": [
    "noadaption_pet = read_data('data/processed/source_P.json')\n",
    "noadaption_pet['train'] = listToString(noadaption_pet, 'unigrams')\n",
    "noadaption_pet = noadaption_pet[noadaption_pet['sentiment'] != '-']\n",
    "acc_P_noadaption = training_vectorising(noadaption_pet, noadaption_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6838235294117647\n",
      "Recall:  0.8454545454545455\n",
      "F1 Score:  0.7560975609756098\n",
      "[  0   2   7   8  10  12  13  20  21  23  24  25  26  28  32  34  37  39\n",
      "  40  48  56  57  63  64  67  72  73  74  75  76  79  85  88  89  92  93\n",
      "  94  98  99 101 104 105 107 117 118 121 134 136 146 148 149 156 162 171\n",
      " 183 184 185 192 198 207]\n"
     ]
    }
   ],
   "source": [
    "noadaption_electronics = read_data('data/processed/source_E.json')\n",
    "noadaption_electronics['train'] = listToString(noadaption_electronics, 'unigrams')\n",
    "noadaption_electronics = noadaption_electronics[noadaption_electronics['sentiment'] != '-']\n",
    "acc_E_noadaption = training_vectorising(noadaption_electronics, noadaption_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sources Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7165354330708661\n",
      "Recall:  0.8272727272727273\n",
      "F1 Score:  0.7679324894514767\n",
      "[  0   2   5   8  12  13  18  21  23  26  32  34  39  40  42  55  57  63\n",
      "  64  67  69  72  75  76  79  85  88  89  93  94  96  98  99 102 105 107\n",
      " 119 121 134 136 146 149 156 157 162 171 176 183 192 195 198 206 207 210\n",
      " 218]\n"
     ]
    }
   ],
   "source": [
    "noadaption_EP = read_data('data/processed/source_EP.json')\n",
    "noadaption_EP['train'] = listToString(noadaption_EP, 'unigrams')\n",
    "noadaption_EP = noadaption_EP[noadaption_EP['sentiment'] != '-']\n",
    "acc_EP_noadaption = training_vectorising(noadaption_EP, noadaption_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.676923076923077\n",
      "Recall:  0.8\n",
      "F1 Score:  0.7333333333333334\n",
      "[  0   4   5   7  11  12  21  23  24  26  28  30  34  37  39  40  43  44\n",
      "  46  48  49  52  55  57  63  64  67  72  73  74  76  85  88  89  92  93\n",
      "  94  96  99 104 105 107 110 121 123 134 136 137 148 150 154 156 160 162\n",
      " 171 176 192 195 196 198 206 210 214 218]\n"
     ]
    }
   ],
   "source": [
    "noadaption_BE = read_data('data/processed/source_BE.json')\n",
    "noadaption_BE['train'] = listToString(noadaption_BE, 'unigrams')\n",
    "noadaption_BE = noadaption_BE[noadaption_BE['sentiment'] != '-']\n",
    "acc_BE_noadaption = training_vectorising(noadaption_BE, noadaption_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7101449275362319\n",
      "Recall:  0.8909090909090909\n",
      "F1 Score:  0.7903225806451614\n",
      "[  0   2   5   7  12  16  21  23  24  26  28  30  32  34  39  40  48  49\n",
      "  52  55  57  63  64  65  67  72  73  74  76  84  85  88  89  92  93  94\n",
      "  96  99 105 107 123 134 136 162 171 192 196 198 207 210 211 215]\n"
     ]
    }
   ],
   "source": [
    "noadaption_BP = read_data('data/processed/source_BP.json')\n",
    "noadaption_BP['train'] = listToString(noadaption_BP, 'unigrams')\n",
    "noadaption_BP = noadaption_BP[noadaption_BP['sentiment'] != '-']\n",
    "acc_BP_noadaption = training_vectorising(noadaption_BP, noadaption_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Sources Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7076923076923077\n",
      "Recall:  0.8363636363636363\n",
      "F1 Score:  0.7666666666666666\n",
      "[  0   2   5  11  12  21  23  24  26  28  32  34  39  40  44  55  57  62\n",
      "  63  64  67  69  72  73  76  79  85  88  89  91  92  93  94  96  99 104\n",
      " 105 107 110 134 135 136 150 157 162 171 176 183 184 195 198 200 206 207\n",
      " 210 211]\n"
     ]
    }
   ],
   "source": [
    "noadaption_BEP = read_data('data/processed/source_BEP.json')\n",
    "noadaption_BEP['train'] = listToString(noadaption_BEP, 'unigrams')\n",
    "noadaption_BEP = noadaption_BEP[noadaption_BEP['sentiment'] != '-']\n",
    "acc_BEP_noadaption = training_vectorising(noadaption_BEP, noadaption_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-domain Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofiaelenaterenziani/opt/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7540983606557377\n",
      "Recall:  0.8363636363636363\n",
      "F1 Score:  0.793103448275862\n",
      "[  0   7  12  16  21  23  26  32  34  39  40  52  55  57  63  64  67  72\n",
      "  76  79  85  89  91  92  94  96  98  99 105 107 123 135 136 137 146 150\n",
      " 157 160 162 171 175 183 195 198 202 206 207 210]\n"
     ]
    }
   ],
   "source": [
    "noadaption_target = read_data('data/processed/target_music.json')\n",
    "noadaption_music = read_data('data/processed/source_music.json')\n",
    "noadaption_target['train'] = listToString(noadaption_target, 'unigrams')\n",
    "noadaption_music['train'] = listToString(noadaption_music, 'unigrams')\n",
    "noadaption_music = noadaption_music[noadaption_music['sentiment'] != '-']\n",
    "acc_music_noadaption = training_vectorising(noadaption_music, noadaption_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-domain Proposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8738738738738738\n",
      "Recall:  0.8818181818181818\n",
      "F1 Score:  0.8778280542986425\n",
      "[  7  17  24  28  34  37  40  52  53  57  72  94  98 105 121 136 148 156\n",
      " 157 162 171 195 202 206 207 210 213]\n"
     ]
    }
   ],
   "source": [
    "source_music = read_data('data/proposed/source_music.json')\n",
    "target_music = read_data('data/proposed/target_music.json')\n",
    "acc_music = training_vectorising(source_music, target_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids_proposed = ['B', 'E', 'P', 'EP', 'BE', 'BP', 'BEP', 'In-domain']\n",
    "model_ids_baseline = ['B', 'E', 'P', 'EP', 'BE', 'BP', 'BEP', 'In-domain']\n",
    "accuracy_proposed = [acc_B, acc_E, acc_P, acc_EP, acc_BE, acc_BP, acc_BEP, acc_music]\n",
    "accuracy_baseline = [acc_B_noadaption, acc_E_noadaption, acc_P_noadaption, acc_EP_noadaption, \n",
    "                     acc_BE_noadaption, acc_BP_noadaption, acc_BEP_noadaption, acc_music_noadaption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = {'Proposed Model ID': model_ids_proposed, 'Baseline Model ID': model_ids_baseline, \n",
    "        'Accuracy Proposed':accuracy_proposed, 'Accuracy Baseline': accuracy_baseline}\n",
    "df = pd.DataFrame(Data,columns=['Proposed Model ID','Accuracy Proposed', 'Baseline Model ID', 'Accuracy Baseline' ])\n",
    "df = df.to_dict(orient='record')\n",
    "write_file('results/', 'classification_experiment.json', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shmae lot artist rioight coming song feel like act shell made good year ago sadly case nickelback welldriven hit right reason like far away saving latest single doesnt feel like cut mustard got ta somebody latest single latest record dark horse doesnt feel like anything spectacular different dissapointment honestly hoping something different chad kroger company didnt strike chord way coldplay shown recently better song nickelback future sunnier dark horse song dnot somebody sounded like one song good music much better new song strong wrong note youre also\n",
      "another cheap thin cd wrapped cardboard cheap send jewel caseanother cheap thin cd wrapped cardboard yet cheap okay wanted disc\n"
     ]
    }
   ],
   "source": [
    "for i in source_music['train'][0:2]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shmae lot artist rioight coming song feel like act shell made good year ago sadly case nickelback welldriven hit right reason like far away saving latest single doesnt feel like cut mustard got ta somebody latest single latest record dark horse doesnt feel like anything spectacular different dissapointment honestly hoping something different chad kroger company didnt strike chord way coldplay shown recently better song nickelback future sunnier dark horse song dnot somebody\n",
      "another cheap thin cd wrapped cardboard cheap send jewel caseanother cheap thin cd wrapped cardboard\n"
     ]
    }
   ],
   "source": [
    "for i in noadaption_music['train'][0:2]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greatgreat song tried need love least liked\n",
      "rotten think dont sell song download disappointed frustratedlove song hate wont download computer system cloud amazon play\n"
     ]
    }
   ],
   "source": [
    "for i in target_music['train'][0:2]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greatgreat song\n",
      "rotten think dont sell song download disappointed frustratedlove song hate wont download\n"
     ]
    }
   ],
   "source": [
    "for i in noadaption_target['train'][0:2]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The code takes forever to run. It is therefore cancelled out. \n",
    "    The results of the experiment can be seen under results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,8): \n",
    "#    source_BEP_test = read_data('test/source_BEP_test{}.json'.format(i))\n",
    "#    target_music_BEP_test = read_data('test/target_music_BEP_test{}.json'.format(i))\n",
    "#    source_BEP_test = source_BEP_test[source_BEP_test['sentiment'] != '-']\n",
    "#    acc_music_multi_test = training_vectorising(source_BEP_test, target_music_BEP_test)\n",
    "#    print(acc_music_multi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_accuracy = [acc_BEP_noadaption, acc_music_multi_test2, acc_music_multi_test3, acc_music_multi_test7, \n",
    "#                acc_music_multi_test1, acc_music_multi_test4, acc_music_multi_test5, acc_music_multi_test6]\n",
    "#lst_size = [0, 59, 108, 587, 1197, 2231, 5171, 9665]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data = {'Glossary Size': lst_size, 'Model Accuracy': lst_accuracy}\n",
    "#df = pd.DataFrame(Data,columns=['Glossary Size','Model Accuracy'])\n",
    "#df = df.to_dict(orient='record')\n",
    "#write_file('results/experiments', 'glossary_experiment_one.json', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The code takes forever to run. It is therefore cancelled out. \n",
    "    The results of the experiment can be seen under results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,9): \n",
    "#    source_BEP_anothertest = read_data('test/source_BEP_anothertest{}.json'.format(i))\n",
    "#    target_music_BEP_anothertest = read_data('test/target_music_BEP_anothertest{}.json'.format(i))\n",
    "#    source_BEP_anothertest = source_BEP_anothertest[source_BEP_anothertest['sentiment'] != '-']\n",
    "#    acc_music_multi_anothertest = training_vectorising(source_BEP_anothertest, target_music_BEP_anothertest)\n",
    "#    print(acc_music_multi_anothertest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_accuracy_2 = [acc_music_multi_anothertest1, acc_music_multi_anothertest2, acc_music_multi_anothertest3,\n",
    "#               acc_music_multi_anothertest4, acc_music_multi_anothertest5, acc_music_multi_anothertest6, \n",
    "#               acc_music_multi_anothertest7, acc_music_multi_anothertest8]\n",
    "#lst_neighbors_2 = [1, 5, 10, 20, 50, 100, 200, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data = {'Neighbors Size': lst_neighbors_2, 'Model Accuracy': lst_accuracy_2}\n",
    "#df = pd.DataFrame(Data,columns=['Neighbors Size','Model Accuracy'])\n",
    "#df = df.to_dict(orient='record')\n",
    "#write_file('results/experiments', 'glossary_experiment_two.json', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
