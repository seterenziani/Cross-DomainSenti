{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json \n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path): \n",
    "    df = pd.read_json(path, lines = True)\n",
    "    return df \n",
    "\n",
    "def write_file(path, file, text): \n",
    "    pathname = os.path.join(path, file)\n",
    "    outfile = open(pathname, 'w')\n",
    "    for instance in text:\n",
    "        outfile.write(json.dumps(instance) + '\\n')\n",
    "    outfile.close()\n",
    "    \n",
    "def flatten_list(df, column): \n",
    "    lst = []\n",
    "    for i in df[column]:\n",
    "        flatten_lst = []\n",
    "        for j in i: \n",
    "            for item in j: \n",
    "                flatten_lst.append(item)\n",
    "        lst.append(flatten_lst)\n",
    "    df[column] = lst\n",
    "    return df \n",
    "\n",
    "def tupleToList(df, column): \n",
    "    tupleToList = []\n",
    "    for i in df[column]: \n",
    "        lst = [list(x) for x in i]\n",
    "        tupleToList.append(lst)\n",
    "    return tupleToList\n",
    "\n",
    "def listToTuples(df, column):\n",
    "    listToTuples = []\n",
    "    for i in df[column]: \n",
    "        lst = []\n",
    "        for j in i: \n",
    "            lst.append(tuple(j))\n",
    "        listToTuples.append(lst)\n",
    "    df[column] = listToTuples\n",
    "    return df\n",
    "\n",
    "def listOfTuplesToListofList(df, column): \n",
    "    listOfTuplesToListofList = []\n",
    "    for i in df[column]: \n",
    "        lst = []\n",
    "        for j in i: \n",
    "            lst.append(list(j)) \n",
    "        listOfTuplesToListofList.append(lst)\n",
    "    df[column] = listOfTuplesToListofList\n",
    "    return df \n",
    "\n",
    "def listToString(df, column): \n",
    "    listToString = []\n",
    "    for i in df[column]:\n",
    "        i = ', '.join(i)\n",
    "        i = ' '.join(s for s in i.split() if not any(c.isdigit() for c in s))\n",
    "        i = i.replace(',', '')\n",
    "        listToString.append(i)\n",
    "    return listToString\n",
    "\n",
    "def remove_sentiment(df, column):\n",
    "    lst = []\n",
    "    for i in df[column]: \n",
    "        output = [j[:-4] if j.endswith('_pos') or j.endswith('_neg') else j for j in i] \n",
    "        lst.append(output)     \n",
    "    df[column] = lst\n",
    "    return df \n",
    "\n",
    "def get_unigramglossary_list(path): \n",
    "    glossary_list = read_data(path) \n",
    "    glossary_list = glossary_list.values.tolist()\n",
    "    return glossary_list\n",
    "\n",
    "def get_bigramglossary_list(path): \n",
    "    glossary_list = read_data(path) \n",
    "    glossary_list = listToTuples(glossary_list, 'similar')\n",
    "    glossary_list['word'] = [tuple(i) for i in glossary_list['word']]\n",
    "    glossary_list = glossary_list.values.tolist()\n",
    "    return glossary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(a, b):\n",
    "    return len(set(a) & set(b))\n",
    "\n",
    "def get_index_glossary(text): \n",
    "    res = []\n",
    "    for i in range(len(glossary_list)): \n",
    "        result =  count_matches(text, glossary_list[i][1])\n",
    "        if len(text) > 1: \n",
    "            result = (result/len(text))*100\n",
    "            res.append(result)\n",
    "        else: \n",
    "            result = (result/1)*100\n",
    "            res.append(result)\n",
    "            \n",
    "    \n",
    "    top_5_idx = np.argsort(res)[::-1][:5]\n",
    "    top_5_values = [res[i] for i in top_5_idx] \n",
    "\n",
    "\n",
    "    res_dic = {}\n",
    "    for key in top_5_idx:\n",
    "        for value in top_5_values:\n",
    "            res_dic[key] = value\n",
    "            top_5_values.remove(value)\n",
    "            break  \n",
    "    return res_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_matches(df, column, threshold, glossary): \n",
    "    lst = []\n",
    "    for i in df[column]: \n",
    "        potential_words = {}\n",
    "        for k,v in i.items(): \n",
    "            k = int(k)\n",
    "            if v >= threshold: \n",
    "                word = glossary[k][0]\n",
    "                potential_words[k] = word\n",
    "            else: \n",
    "                potential_words[k] = 'None'\n",
    "        lst.append(potential_words)   \n",
    "\n",
    "    all_words = []\n",
    "    for i in lst:\n",
    "        words = []\n",
    "        for k,v in i.items():\n",
    "            words.append(v)\n",
    "        all_words.append(words) \n",
    "    \n",
    "    new_allwords = []\n",
    "    for i in all_words: \n",
    "        new_words = []\n",
    "        for j in i: \n",
    "            if j != 'None': \n",
    "                new_words.append(j)\n",
    "        new_allwords.append(new_words) \n",
    "    return new_allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_unigrams(path1, threshold): \n",
    "    source = read_data(path1)\n",
    "    print('Finding Matches ....')\n",
    "    source['matches'] = source['sentiment_unigrams'].apply(lambda x:get_index_glossary(x))\n",
    "    print('Finding Proposed Unigrams ...')\n",
    "    source['proposed_unigrams'] = get_word_matches(source, 'matches', threshold, glossary_list)\n",
    "    return source \n",
    "\n",
    "def potential_bigrams(df, threshold): \n",
    "    df = listToTuples(df, 'sentiment_bigrams')\n",
    "    print('Finding matches bigrams....')\n",
    "    df['matches_bigrams'] = df['sentiment_bigrams'].apply(lambda x:get_index_glossary(x))\n",
    "    print('Finding proposed bigrams ...')\n",
    "    df['proposed_bigrams'] = get_word_matches(df, 'matches_bigrams', threshold, glossary_list)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_instances(df): \n",
    "    df = df.drop('matches', axis = 1)\n",
    "    df = df.drop('matches_bigrams', axis = 1)\n",
    "    df = listOfTuplesToListofList(df, 'proposed_bigrams')\n",
    "    df = flatten_list(df, 'proposed_bigrams')\n",
    "    df['train'] = df['unigrams'] + df['proposed_bigrams'] + df['proposed_unigrams']\n",
    "    df = remove_sentiment(df, 'train')\n",
    "    df['train'] = listToString(df, 'train')\n",
    "    proposed_data = df.to_dict(orient='record')\n",
    "    return proposed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/music_unigram_glossary.json')\n",
    "source_music = potential_unigrams('data/processed/source_music.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/book_unigram_glossary.json')\n",
    "source_B = potential_unigrams('data/processed/source_B.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/electronics_unigram_glossary.json')\n",
    "source_E = potential_unigrams('data/processed/source_E.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/pet_unigram_glossary.json')\n",
    "source_P = potential_unigrams('data/processed/source_P.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/EP_unigram_glossary.json')\n",
    "source_EP = potential_unigrams('data/processed/source_EP.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/BE_unigram_glossary.json')\n",
    "source_BE = potential_unigrams('data/processed/source_BE.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/BP_unigram_glossary.json')\n",
    "source_BP = potential_unigrams('data/processed/source_BP.json', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/multisource_unigram_glossary.json')\n",
    "source_BEP = potential_unigrams('data/processed/source_BEP.json', threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/music_bigram_glossary.json')\n",
    "source_music = potential_bigrams(source_music, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/books_bigram_glossary.json')\n",
    "source_B = potential_bigrams(source_B, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/electronics_bigram_glossary.json')\n",
    "source_E = potential_bigrams(source_E, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/pet_bigram_glossary.json')\n",
    "source_P = potential_bigrams(source_P, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/EP_bigram_glossary.json')\n",
    "source_EP = potential_bigrams(source_EP, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/BE_bigram_glossary.json')\n",
    "source_BE = potential_bigrams(source_BE,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/BP_bigram_glossary.json')\n",
    "source_BP = potential_bigrams(source_BP, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_bigramglossary_list('data/glossary/multisource_bigram_glossary.json')\n",
    "source_BEP = potential_bigrams(source_BEP, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_music = get_training_instances(source_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_B = get_training_instances(source_B)\n",
    "source_E = get_training_instances(source_E)\n",
    "source_P = get_training_instances(source_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_BE = get_training_instances(source_BE)\n",
    "source_EP = get_training_instances(source_EP)\n",
    "source_BP = get_training_instances(source_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_BEP = get_training_instances(source_BEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file('data/proposed/', 'source_B.json', source_B)\n",
    "write_file('data/proposed/', 'source_E.json', source_E)\n",
    "write_file('data/proposed/', 'source_P.json', source_P)\n",
    "\n",
    "write_file('data/proposed/', 'source_BE.json', source_BE)\n",
    "write_file('data/proposed/', 'source_BP.json', source_BP)\n",
    "write_file('data/proposed/', 'source_EP.json', source_EP)\n",
    "\n",
    "write_file('data/proposed/', 'source_BEP.json', source_BEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file('data/proposed/', 'source_music.json', source_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_training_test(df):    \n",
    "#    df = df.drop('matches', axis = 1)\n",
    "#    df = df.drop('sentiment_bigrams', axis = 1)\n",
    "#    df['train'] = df['unigrams'] + df['proposed_unigrams']\n",
    "#    df = remove_sentiment(df, 'train')\n",
    "#    df['train'] = listToString(df, 'train')\n",
    "#    proposed_data = df.to_dict(orient='record')\n",
    "#    return proposed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = 6\n",
    "#for i in range(1,7):\n",
    "#    glossary_list = get_unigramglossary_list('test/multisource_unigram_glossary_test{}.json'.format(i))\n",
    "#    source_BEP_test = potential_unigrams('data/processed/source_BEP.json', threshold)\n",
    "#    source_BEP_test = get_training_test(source_BEP_test)\n",
    "#    write_file('test/', 'glossary_source_BEP_test{}.json'.format(i), source_BEP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = 6\n",
    "#for i in range(1,9):\n",
    "#    glossary_list = get_unigramglossary_list('test/multisource_unigram_glossary_anothertest{}.json'.format(i))\n",
    "#    source_BEP_anothertest = potential_unigrams('data/processed/source_BEP.json', threshold)\n",
    "#    source_BEP_anothertest = get_training_test(source_BEP_anothertest)\n",
    "#    write_file('test/', 'glossary_source_BEP_anothertest{}.json'.format(i), source_BEP_anothertest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
