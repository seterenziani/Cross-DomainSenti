{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from zipfile import ZipFile\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_NaN(file): \n",
    "    \"\"\"\n",
    "    Function that takes a json.giz file as input and counts the number of missing values. \n",
    "    The function searches for missing values by converting the json.giz file into a pandas dataframe. \n",
    "    \"\"\"\n",
    "    final_columns = ['reviewText', 'summary', 'sentiment']\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    df = df.drop(columns = [col for col in df if col not in final_columns]) \n",
    "    for i in final_columns: \n",
    "        print(df[i].isnull().sum())\n",
    "\n",
    "def print_json(file): \n",
    "    for line in gzip.open(file):\n",
    "        review_data = json.loads(line)\n",
    "        for key in review_data:\n",
    "            print('\"' + key +'\": ' + str(review_data[key]))\n",
    "        break\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    df = df[df['reviewText'].notnull()]\n",
    "    df = df[df['sentiment'].notnull()]\n",
    "    df.loc[df['sentiment'] == 'positive', 'sentiment'] = 1\n",
    "    df.loc[df['sentiment'] == 'negative', 'sentiment'] = 0\n",
    "    df['train'] = df['reviewText'].str.lower() + ' ' + df['summary'].str.lower()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_vectorising (source, target): \n",
    "    # convert training data to bag of words\n",
    "    cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2), stop_words='english')\n",
    "    X_train_cv = cv.fit_transform(source['train'].values.astype('U'))\n",
    "    X_test_cv = cv.transform(target['train'].values.astype('U'))\n",
    "    Y_train = source['sentiment'].astype('int')\n",
    "    Y_test = target['sentiment'].astype('int')\n",
    "    \n",
    "    # train model and generate predictions\n",
    "    model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    model.fit(X_train_cv, Y_train)\n",
    "    train_yhat = model.predict(X_train_cv)\n",
    "    train_acc = accuracy_score(Y_train, train_yhat)\n",
    "    test_yhat = model.predict(X_test_cv)\n",
    "    test_acc = accuracy_score(Y_test, test_yhat)\n",
    "    \n",
    "    \n",
    "    # compute f-1 score\n",
    "    #score = np.round(f1_score(target['sentiment'].astype('int'), y_pred, average='micro'),4)\n",
    "    #score_training = np.round(f1_score(source['sentiment'].astype('int'), y_pred, average='micro'),4)\n",
    "    precision = precision_score(Y_test, test_yhat, labels=[1,2], average='micro')\n",
    "    recall = recall_score(Y_test, test_yhat, labels=[1,2], average='micro')\n",
    "    misclassified_samples = np.flatnonzero(Y_test != test_yhat)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Accuracy test: \", test_acc)\n",
    "    return test_acc, test_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading files as dataframes \n",
    "df_train = pd.read_json('data/classification/music_reviews_train.json.gz', lines=True)\n",
    "df_dev = pd.read_json('data/classification/music_reviews_dev.json.gz', lines=True)\n",
    "df_test = pd.read_json('data/classification/music_reviews_test_masked.json.gz', lines=True)\n",
    "df_hardcases = pd.read_json('data/classification/music_reviews_hardcases.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processing(df_train)\n",
    "df_dev = processing(df_dev)\n",
    "df_hardcases = processing(df_hardcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.906874365052489\n",
      "Recall:  0.9427917620137299\n",
      "Accuracy test:  0.9124649859943977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9124649859943977, array([0, 0, 0, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectorising(df_train, df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2), stop_words='english')\n",
    "X_train_cv = cv.fit_transform(df_train['train'].values.astype('U'))\n",
    "X_test_cv = cv.transform(df_hardcases['train'].values.astype('U'))\n",
    "Y_train = df_train['sentiment'].astype('int')\n",
    "\n",
    "# train model and generate predictions\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train_cv, Y_train)\n",
    "test_yhat = model.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hardcases['sentiment'] = test_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2), stop_words='english')\n",
    "X_train_cv = cv.fit_transform(df_train['train'].values.astype('U'))\n",
    "X_test_cv = cv.transform(df_test['train'].values.astype('U'))\n",
    "Y_train = df_train['sentiment'].astype('int')\n",
    "\n",
    "# train model and generate predictions\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train_cv, Y_train)\n",
    "test_yhat_test = model.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sentiment'] = test_yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating json document \n",
    "output = df_test.to_dict(orient='record')\n",
    "outFile = open('music_reviews_test.json', 'w')\n",
    "for instance in output:\n",
    "    outFile.write(json.dumps(instance) + '\\n')\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df_hardcases.to_dict(orient='record')\n",
    "outFile = open('phase2_testData.json', 'w')\n",
    "for instance in output:\n",
    "    outFile.write(json.dumps(instance) + '\\n')\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving in a zipfile \n",
    "zipObj = ZipFile('phase2_testData-masked.json.zip', 'w')\n",
    "zipObj.write('phase2_testData.json')\n",
    "zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving in a zipfile \n",
    "zipObj = ZipFile('music_reviews_prediction_hardcases.json.zip', 'w')\n",
    "zipObj.write('music_reviews_prediction_hardcases.json')\n",
    "zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
