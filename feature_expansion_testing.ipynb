{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json \n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path): \n",
    "    df = pd.read_json(path, lines = True)\n",
    "    return df \n",
    "\n",
    "def write_file(path, file, text): \n",
    "    pathname = os.path.join(path, file)\n",
    "    outfile = open(pathname, 'w')\n",
    "    for instance in text:\n",
    "        outfile.write(json.dumps(instance) + '\\n')\n",
    "    outfile.close()\n",
    "    \n",
    "def flatten_list(df, column): \n",
    "    lst = []\n",
    "    for i in df[column]:\n",
    "        flatten_lst = []\n",
    "        for j in i: \n",
    "            for item in j: \n",
    "                flatten_lst.append(item)\n",
    "        lst.append(flatten_lst)\n",
    "    df[column] = lst\n",
    "    return df \n",
    "\n",
    "def tupleToList(df, column): \n",
    "    tupleToList = []\n",
    "    for i in df[column]: \n",
    "        lst = [list(x) for x in i]\n",
    "        tupleToList.append(lst)\n",
    "    return tupleToList\n",
    "\n",
    "def listToTuples(df, column):\n",
    "    listToTuples = []\n",
    "    for i in df[column]: \n",
    "        lst = []\n",
    "        for j in i: \n",
    "            lst.append(tuple(j))\n",
    "        listToTuples.append(lst)\n",
    "    df[column] = listToTuples\n",
    "    return df\n",
    "\n",
    "def listOfTuplesToListofList(df, column): \n",
    "    listOfTuplesToListofList = []\n",
    "    for i in df[column]: \n",
    "        lst = []\n",
    "        for j in i: \n",
    "            lst.append(list(j)) \n",
    "        listOfTuplesToListofList.append(lst)\n",
    "    df[column] = listOfTuplesToListofList\n",
    "    return df \n",
    "\n",
    "def listToString(df, column): \n",
    "    listToString = []\n",
    "    for i in df[column]:\n",
    "        i = ', '.join(i)\n",
    "        i = ' '.join(s for s in i.split() if not any(c.isdigit() for c in s))\n",
    "        i = i.replace(',', '')\n",
    "        listToString.append(i)\n",
    "    return listToString\n",
    "\n",
    "def remove_sentiment(df, column):\n",
    "    lst = []\n",
    "    for i in df[column]: \n",
    "        output = [j[:-4] if j.endswith('_pos') or j.endswith('_neg') else j for j in i] \n",
    "        lst.append(output)     \n",
    "    df[column] = lst\n",
    "    return df \n",
    "\n",
    "def get_unigramglossary_list(path): \n",
    "    glossary_list = read_data(path) \n",
    "    glossary_list = glossary_list.values.tolist()\n",
    "    return glossary_list\n",
    "\n",
    "def get_bigramglossary_list(path): \n",
    "    glossary_list = read_data(path) \n",
    "    glossary_list = listToTuples(thesaurus_list, 'similar')\n",
    "    glossary_list['word'] = [tuple(i) for i in glossary_list['word']]\n",
    "    glossary_list = glossary_list.values.tolist()\n",
    "    return glossary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(a, b):\n",
    "    return len(set(a) & set(b))\n",
    "\n",
    "def get_index_glossary(text): \n",
    "    res = []\n",
    "    for i in range(len(glossary_list)): \n",
    "        result =  count_matches(text, glossary_list[i][1])\n",
    "        if len(text) > 1: \n",
    "            result = (result/len(text))*100\n",
    "            res.append(result)\n",
    "        else: \n",
    "            result = (result/1)*100\n",
    "            res.append(result)\n",
    "            \n",
    "    \n",
    "    top_5_idx = np.argsort(res)[::-1][:5]\n",
    "    top_5_values = [res[i] for i in top_5_idx] \n",
    "\n",
    "\n",
    "    res_dic = {}\n",
    "    for key in top_5_idx:\n",
    "        for value in top_5_values:\n",
    "            res_dic[key] = value\n",
    "            top_5_values.remove(value)\n",
    "            break  \n",
    "    return res_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_matches(df, column, threshold, glossary): \n",
    "    lst = []\n",
    "    for i in df[column]: \n",
    "        potential_words = {}\n",
    "        for k,v in i.items(): \n",
    "            k = int(k)\n",
    "            if v >= threshold: \n",
    "                word = glossary[k][0]\n",
    "                potential_words[k] = word\n",
    "            else: \n",
    "                potential_words[k] = 'None'\n",
    "        lst.append(potential_words)   \n",
    "\n",
    "    all_words = []\n",
    "    for i in lst:\n",
    "        words = []\n",
    "        for k,v in i.items():\n",
    "            words.append(v)\n",
    "        all_words.append(words) \n",
    "    \n",
    "    new_allwords = []\n",
    "    for i in all_words: \n",
    "        new_words = []\n",
    "        for j in i: \n",
    "            if j != 'None': \n",
    "                new_words.append(j)\n",
    "        new_allwords.append(new_words) \n",
    "    return new_allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_unigrams(path1, threshold): \n",
    "    source = read_data(path1)\n",
    "    print('Finding Matches ....')\n",
    "    source['matches'] = source['sentiment_unigrams'].apply(lambda x:get_index_glossary(x))\n",
    "    print('Finding Proposed Unigrams ...')\n",
    "    source['proposed_unigrams'] = get_word_matches(source, 'matches', threshold, glossary_list)\n",
    "    return source \n",
    "\n",
    "def potential_bigrams(df, threshold): \n",
    "    df = listToTuples(df, 'sentiment_bigrams')\n",
    "    print('Finding matches bigrams....')\n",
    "    df['matches_bigrams'] = df['sentiment_bigrams'].apply(lambda x:get_index_glossary(x))\n",
    "    print('Finding proposed bigrams ...')\n",
    "    df['proposed_bigrams'] = get_word_matches(df, 'matches_bigrams', threshold, glossary_list)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_instances(df): \n",
    "    df = df.drop('matches', axis = 1)\n",
    "    df = df.drop('matches_bigrams', axis = 1)\n",
    "    df = listOfTuplesToListofList(df, 'proposed_bigrams')\n",
    "    df = flatten_list(df, 'proposed_bigrams')\n",
    "    df['train'] = df['unigrams'] + df['proposed_bigrams'] + df['proposed_unigrams']\n",
    "    df = remove_sentiment(df, 'train')\n",
    "    df['train'] = listToString(df, 'train')\n",
    "    proposed_data = df.to_dict(orient='record')\n",
    "    return proposed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/music_unigram_glossary.json')\n",
    "target_music = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/book_unigram_glossary.json')\n",
    "target_music_B = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/electronics_unigram_glossary.json')\n",
    "target_music_E = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/pet_unigram_glossary.json')\n",
    "target_music_P = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/BE_unigram_glossary.json')\n",
    "target_music_BE = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/BP_unigram_glossary.json')\n",
    "target_music_BP = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/EP_unigram_glossary.json')\n",
    "target_music_EP = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Matches ....\n",
      "Finding Proposed Unigrams ...\n"
     ]
    }
   ],
   "source": [
    "glossary_list = get_unigramglossary_list('data/glossary/multisource_unigram_glossary.json')\n",
    "target_music_BEP = potential_unigrams('data/processed/target_music.json', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/music_bigram_glossary.json')\n",
    "target_music = potential_bigrams(target_music, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/books_bigram_glossary.json')\n",
    "target_music_B = potential_bigrams(target_music_B, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/electronics_bigram_glossary.json')\n",
    "target_music_E = potential_bigrams(target_music_E, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/pet_bigram_glossary.json')\n",
    "target_music_P = potential_bigrams(target_music_P, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/BE_bigram_glossary.json')\n",
    "target_music_BE = potential_bigrams(target_music_BE, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/BP_bigram_glossary.json')\n",
    "target_music_BP = potential_bigrams(target_music_BP, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/EP_bigram_glossary.json')\n",
    "target_music_EP = potential_bigrams(target_music_EP, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches bigrams....\n",
      "Finding proposed bigrams ...\n"
     ]
    }
   ],
   "source": [
    "thesaurus_list = get_bigramthesaurus_list('data/glossary/multisource_bigram_glossary.json')\n",
    "target_music_BEP = potential_bigrams(target_music_BEP, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_music_B = get_training_instances(target_music_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_music_E = get_training_instances(target_music_E)\n",
    "target_music_P = get_training_instances(target_music_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4e01c9f9c666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_music_BP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_music_BP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget_music_EP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_music_EP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-fe53b769d977>\u001b[0m in \u001b[0;36mget_training_instances\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_training_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches_bigrams'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistOfTuplesToListofList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proposed_bigrams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proposed_bigrams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "target_music_BE = get_training_instances(target_music_BE)\n",
    "target_music_BP = get_training_instances(target_music_BP)\n",
    "target_music_EP = get_training_instances(target_music_EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-90da7912e535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_music_BEP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_music_BEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-fe53b769d977>\u001b[0m in \u001b[0;36mget_training_instances\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_training_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches_bigrams'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistOfTuplesToListofList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proposed_bigrams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proposed_bigrams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "target_music_BEP = get_training_instances(target_music_BEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_music = get_training_instances(target_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file('data/proposed/', 'target_music_B.json', target_music_B)\n",
    "write_file('data/proposed/', 'target_music_E.json', target_music_E)\n",
    "write_file('data/proposed/', 'target_music_P.json', target_music_P)\n",
    "\n",
    "write_file('data/proposed/', 'target_music_BP.json', target_music_BP)\n",
    "write_file('data/proposed/', 'target_music_BE.json', target_music_BE)\n",
    "write_file('data/proposed/', 'target_music_EP.json', target_music_EP)\n",
    "\n",
    "write_file('data/proposed/', 'target_music_BEP.json', target_music_BEP)\n",
    "write_file('data/proposed/', 'target_music.json', target_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file('data/proposed/', 'target_music_B.json', target_music_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_training_test(df) :   \n",
    "#    df = df.drop('matches', axis = 1)\n",
    "#    df['train'] = df['unigrams'] + df['proposed_unigrams']\n",
    "#    df = remove_sentiment(df, 'train')\n",
    "#    df['train'] = listToString(df, 'train')\n",
    "#    proposed_data = df.to_dict(orient='record')\n",
    "#    return proposed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = 6\n",
    "#for i in range(1,8):\n",
    "#    thesaurus_list = get_unigramthesaurus_list('test/multisource_unigram_glossary_test{}.json'.format(i))\n",
    "#    target_music_BEP_test = potential_unigrams('data/processed/target_music.json', threshold)\n",
    "#    target_music_BEP_test = get_training_test(target_music_BEP_test)\n",
    "#    write_file('test/', 'target_music_BEP_test{}.json'.format(i), target_music_BEP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = 6\n",
    "#for i in range(1,8):\n",
    "#    thesaurus_list = get_unigramthesaurus_list('test/multisource_unigram_glossary_test{}.json'.format(i))\n",
    "#    target_music_BEP_anothertest = potential_unigrams('data/processed/target_music.json', threshold)\n",
    "#    target_music_BEP_anothertest = get_training_test(target_music_BEP_anothertest)\n",
    "#    write_file('test/', 'target_music_BEP_anothertest{}.json'.format(i), target_music_BEP_anothertest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
